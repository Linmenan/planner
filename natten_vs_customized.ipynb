{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d743edc-79f6-49f4-8059-8d45c0c6adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natten import NeighborhoodAttention1D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9246766-7733-4dfb-8fa0-5cc24e8069c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_trajectory(length, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    生成一条模拟轨迹数据：\n",
    "      - x 坐标从 0 到 length-1 的线性变化\n",
    "      - y 坐标基于一个正弦曲线，再加上一些噪声\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, 10, length)  # x 坐标范围\n",
    "    y = np.sin(x) + np.random.normal(scale=noise_std, size=length)\n",
    "    # 将 x, y 拼接成 (length, 2)\n",
    "    traj = np.stack([x, y], axis=-1)\n",
    "    return traj.astype(np.float32)\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, num_samples, seq_len):\n",
    "        super(TrajectoryDataset, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.seq_len = seq_len\n",
    "        # 构造数据：每个样本是一条轨迹\n",
    "        self.data = [generate_trajectory(seq_len) for _ in range(num_samples)]\n",
    "        # 目标可以设计为平滑后的轨迹，或者预测未来轨迹，这里我们简单将目标设为原轨迹（自监督）\n",
    "        self.target = self.data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 返回 shape: (seq_len, 2)\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.target[idx])\n",
    "\n",
    "# 构造数据集和 DataLoader\n",
    "num_samples = 1024\n",
    "seq_len = 50  # 序列长度\n",
    "batch_size = 32\n",
    "train_dataset = TrajectoryDataset(num_samples, seq_len)\n",
    "val_dataset = TrajectoryDataset(256, seq_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 假设我们的模型输入输出维度为 2（x, y），或者可以先通过一个线性层映射到更高维度\n",
    "class SimpleAttentionModel(nn.Module):\n",
    "    def __init__(self, attn_module, dim):\n",
    "        super(SimpleAttentionModel, self).__init__()\n",
    "        self.attn = attn_module\n",
    "        self.fc = nn.Linear(dim, dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, L, dim)\n",
    "        out = self.attn(x, x, x)  # 对于自注意力，query, key, value 均为 x\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6c97c-3ffc-4c7b-a944-afa59377d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedNeighborhoodAttention1D_MH(nn.Module):\n",
    "    def __init__(self, radius, dim, num_heads, qkv_bias=True, attn_drop=0.0, proj_drop=0.0):\n",
    "        \"\"\"\n",
    "        多头邻域注意力模块。\n",
    "        参数：\n",
    "            radius: int，邻域半径（窗口大小 = 2*radius + 1）\n",
    "            dim: int，输入特征总维度\n",
    "            num_heads: int，多头数，要求 dim % num_heads == 0\n",
    "            qkv_bias: bool，是否有偏置\n",
    "            attn_drop, proj_drop: dropout 概率\n",
    "        \"\"\"\n",
    "        super(CustomizedNeighborhoodAttention1D_MH, self).__init__()\n",
    "        self.radius = radius\n",
    "        self.window_size = 2 * radius + 1\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = math.sqrt(self.head_dim)\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        参数：\n",
    "            x: Tensor, shape = (B, L, dim)\n",
    "        返回：\n",
    "            out: Tensor, shape = (B, L, dim)\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "        # 生成 q, k, v\n",
    "        qkv = self.qkv(x)  # (B, L, 3*dim)\n",
    "        # print(f\"qkv.shape = {qkv.shape}\")\n",
    "        qkv = qkv.reshape(B, L, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)  # (3, B, num_heads, L, head_dim)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # each: (B, num_heads, L, head_dim)\n",
    "        # 将 B 和 num_heads 合并\n",
    "        q = q.reshape(B * self.num_heads, L, self.head_dim)\n",
    "        k = k.reshape(B * self.num_heads, L, self.head_dim)\n",
    "        v = v.reshape(B * self.num_heads, L, self.head_dim)\n",
    "        \n",
    "        # 对 k 和 v 沿序列维度填充，使得每个位置都可以构造一个完整的局部窗口\n",
    "        # 首先将 k,v 转置为 (B', head_dim, L)\n",
    "        k_t = k.transpose(1, 2)\n",
    "        v_t = v.transpose(1, 2)\n",
    "        # 填充最后一维（原来的 L 维），pad=(left, right)\n",
    "        k_padded = F.pad(k_t, pad=(self.radius, self.radius), mode='constant', value=0)\n",
    "        v_padded = F.pad(v_t, pad=(self.radius, self.radius), mode='constant', value=0)\n",
    "        # 转回来 (B', L+2*radius, head_dim)\n",
    "        k_padded = k_padded.transpose(1, 2)\n",
    "        v_padded = v_padded.transpose(1, 2)\n",
    "        # print(f\"k = {k}\")\n",
    "        # print(f\"k_padded = {k_padded}\")\n",
    "        # print(f\"v = {v}\")\n",
    "        # print(f\"v_padded = {v_padded}\")\n",
    "        # 使用 unfold 在序列维度提取局部窗口，得到 (B', L, window_size, head_dim)\n",
    "        k_windows = k_padded.unfold(dimension=1, size=self.window_size, step=1)\n",
    "        v_windows = v_padded.unfold(dimension=1, size=self.window_size, step=1)\n",
    "        # print(f\"k = {k}\")\n",
    "        # print(f\"k_windows = {k_windows}\")\n",
    "        # print(f\"v = {v}\")\n",
    "        # print(f\"v_windows = {v_windows}\")\n",
    "        \n",
    "        # 如果 unfold 结果形状为 (B', L, head_dim, window_size) 则需要转置最后两个维度\n",
    "        if k_windows.shape[-2] == self.head_dim and k_windows.shape[-1] == self.window_size:\n",
    "            k_windows = k_windows.transpose(-2, -1)\n",
    "            v_windows = v_windows.transpose(-2, -1)\n",
    "        \n",
    "        # 计算注意力分数：点积\n",
    "        # q: (B', L, head_dim) 自动扩展为 (B', L, 1, head_dim)\n",
    "        # k_windows: (B', L, window_size, head_dim)\n",
    "        scores = torch.einsum('bld,blwd->blw', q, k_windows) / self.scale  # (B', L, window_size)\n",
    "        # print(f\"scores = {scores}\")\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        # print(f\"attn = {attn}\")\n",
    "        attn = self.attn_drop(attn)\n",
    "        # print(f\"attn_drop = {attn}\")\n",
    "        # 加权求和，输出 (B', L, head_dim)\n",
    "        out = torch.einsum('blw,blwd->bld', attn, v_windows)\n",
    "        # 还原形状 (B, num_heads, L, head_dim)\n",
    "        out = out.reshape(B, self.num_heads, L, self.head_dim)\n",
    "        # 合并头 (B, L, dim)\n",
    "        out = out.transpose(1, 2).reshape(B, L, self.dim)\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8141f4b-38a9-48af-8155-64866e0a4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 简单模型封装 --------------------\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, attn_module, dim):\n",
    "        \"\"\"\n",
    "        使用指定的邻域注意力模块封装一个简单的模型，\n",
    "        模型结构：输入 -> Attention -> 全连接层 -> 输出\n",
    "        假设任务为回归，输入和输出形状均为 (B, L, dim)\n",
    "        \"\"\"\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.attn = attn_module\n",
    "        self.fc = nn.Linear(self.dim, self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, dim)\n",
    "        out = self.attn(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# -------------------- 构造数据集 --------------------\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, num_samples, L, dim):\n",
    "        super(SyntheticDataset, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.L = L\n",
    "        self.dim = dim\n",
    "        # 构造输入数据：随机数\n",
    "        self.data = torch.randn(num_samples, L, dim)\n",
    "        # 构造目标数据：例如一个线性函数 + 非线性激活（模拟一定关系）\n",
    "        # 这里我们设定目标 = sin(数据的线性组合)\n",
    "        weight = torch.randn(dim, dim)\n",
    "        bias = torch.randn(dim)\n",
    "        self.target = torch.sin(self.data.matmul(weight) + bias)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1483c19-264a-43b8-9662-2289e0e5af79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "BATCH_SIZE = 1\n",
    "L = 8\n",
    "DIM = 10\n",
    "NUM_HEADS = 2\n",
    "RADIUS = 1\n",
    "NUM_TRAIN = 1\n",
    "NUM_VAL = 1\n",
    "EPOCHS = 1\n",
    "LR = 1e-3\n",
    "\n",
    "# 构造数据集和数据加载器\n",
    "train_dataset = SyntheticDataset(NUM_TRAIN, L, DIM)\n",
    "val_dataset = SyntheticDataset(NUM_VAL, L, DIM)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# -------------------- 构造两个模型 --------------------\n",
    "# 经典 natten 版本（假设支持多头，并且参数名称类似，下列参数需根据实际natten版本调整）\n",
    "classic_natten = NeighborhoodAttention1D(\n",
    "    dim=DIM,\n",
    "    kernel_size=2 * RADIUS + 1,\n",
    "    dilation=1,\n",
    "    num_heads=NUM_HEADS,\n",
    "    qkv_bias=True,\n",
    "    qk_scale=None,\n",
    "    attn_drop=0.0,\n",
    "    proj_drop=0.0\n",
    ")\n",
    "model_classic = AttentionModel(classic_natten,DIM)\n",
    "\n",
    "# 自定义实现\n",
    "custom_natten = CustomizedNeighborhoodAttention1D_MH(\n",
    "    radius=RADIUS,\n",
    "    dim=DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    qkv_bias=True,\n",
    "    attn_drop=0.0,\n",
    "    proj_drop=0.0\n",
    ")\n",
    "model_custom = AttentionModel(custom_natten,DIM)\n",
    "\n",
    "# 将模型放到相同设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_classic = model_classic.to(device)\n",
    "model_custom = model_custom.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_classic = torch.optim.Adam(model_classic.parameters(), lr=LR)\n",
    "optimizer_custom = torch.optim.Adam(model_custom.parameters(), lr=LR)\n",
    "\n",
    "# -------------------- 训练过程 --------------------\n",
    "def train_one_epoch(model, optimizer, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y in loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch_x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            out = model(batch_x)\n",
    "            loss = criterion(out, batch_y)\n",
    "            total_loss += loss.item() * batch_x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "print(\"Training Classic Natten Model...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_train = train_one_epoch(model_classic, optimizer_classic, train_loader)\n",
    "    loss_val = evaluate(model_classic, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {loss_train:.4f}, Val Loss: {loss_val:.4f}\")\n",
    "\n",
    "print(\"Training Customized Natten Model...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_train = train_one_epoch(model_custom, optimizer_custom, train_loader)\n",
    "    loss_val = evaluate(model_custom, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {loss_train:.4f}, Val Loss: {loss_val:.4f}\")\n",
    "\n",
    "# -------------------- 使用相同数据进行验证，并可视化部分结果 --------------------\n",
    "# 取一个验证批次\n",
    "model_classic.eval()\n",
    "model_custom.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        out_classic = model_classic(batch_x)  # (B, L, DIM)\n",
    "        out_custom = model_custom(batch_x)\n",
    "        break\n",
    "\n",
    "# 选取第一个样本的第一个序列的位置，将输出结果的前两个维度视为 (x, y) 坐标进行可视化\n",
    "# 这里我们简单假设输出的第2个维度即为 y 坐标，前者为 x 坐标（仅作为示例）\n",
    "sample_classic = out_classic[0].cpu().numpy()\n",
    "sample_custom = out_custom[0].cpu().numpy()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 生成连接线数据\n",
    "pair_x = []\n",
    "pair_y = []\n",
    "L = sample_classic.shape[0]\n",
    "for i in range(L):\n",
    "    # 连接对应点：经典 -> 自定义\n",
    "    pair_x.extend([sample_classic[i, 0], sample_custom[i, 0], None])\n",
    "    pair_y.extend([sample_classic[i, 1], sample_custom[i, 1], None])\n",
    "\n",
    "# 绘制图像\n",
    "fig = go.Figure()\n",
    "\n",
    "# 绘制经典输出的散点（不连接成线）\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sample_classic[:, 0],\n",
    "    y=sample_classic[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue'),\n",
    "    name='Classic Natten'\n",
    "))\n",
    "\n",
    "# 绘制自定义输出的散点\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sample_custom[:, 0],\n",
    "    y=sample_custom[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(color='red'),\n",
    "    name='Customized Natten'\n",
    "))\n",
    "\n",
    "# 绘制每个对应点之间的连线\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=pair_x,\n",
    "    y=pair_y,\n",
    "    mode='lines',\n",
    "    line=dict(color='green'),\n",
    "    name='Pair Connection'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pairwise Connection between Classic and Customized Outputs\",\n",
    "    xaxis_title=\"X\",\n",
    "    yaxis_title=\"Y\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1)\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planscope",
   "language": "python",
   "name": "planscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
